{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557bc264",
   "metadata": {
    "id": "557bc264"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec9a11-3515-40aa-97ac-73c249df560e",
   "metadata": {
    "id": "a4ec9a11-3515-40aa-97ac-73c249df560e"
   },
   "source": [
    "# Group Number: group visiha\n",
    "# Student 1: Sidney Damen\n",
    "# Student 2: Haoqi Guo\n",
    "# Student 3: Victor Wen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c200a7-b3ab-4c9a-bcf8-320271c040f3",
   "metadata": {
    "id": "a8c200a7-b3ab-4c9a-bcf8-320271c040f3"
   },
   "source": [
    "In case you are using google colab, uncomment the following cell, and modify the ```notebook_dir``` variable to contain the directory this notebook is in. It will automatically download the .py files needed for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "igFRsZKIC18S",
   "metadata": {
    "id": "igFRsZKIC18S"
   },
   "outputs": [],
   "source": [
    "# Change the following  line to the directory this notebook is (if using colab)\n",
    "# In case you do not know the path, open the file navigator on the left in colab\n",
    "# Find the folder containing this notebook, then press on the three dots --> copy path\n",
    "notebook_dir = \"/content/drive/MyDrive/Colab Notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828246d4-75b2-42b7-ab06-925e6624f411",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "828246d4-75b2-42b7-ab06-925e6624f411",
    "outputId": "6b8c8a78-a788-4fec-b151-fa279e81c0ff"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT IF USING COLAB\n",
    "from google.colab import drive\n",
    "import requests\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, notebook_dir) \n",
    "os.chdir(notebook_dir)\n",
    "symco = \"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/symconv.py?raw=true\"\n",
    "crpt = \"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/carpet.py?raw=true\"\n",
    "r_s = requests.get(symco, allow_redirects=True)\n",
    "r_c = requests.get(crpt, allow_redirects=True)\n",
    "with open('symconv.py', 'wb') as f:\n",
    "    f.write(r_s.content)\n",
    "with open('carpet.py', 'wb') as f:\n",
    "    f.write(r_c.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c401bd6-3828-4f5e-ada8-a026e0a167bf",
   "metadata": {
    "id": "1c401bd6-3828-4f5e-ada8-a026e0a167bf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import symconv as sc\n",
    "from carpet import show_carpet, oh_to_label\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0bcb8-5215-40b3-8ba2-7e4208651c90",
   "metadata": {
    "id": "35c0bcb8-5215-40b3-8ba2-7e4208651c90"
   },
   "outputs": [],
   "source": [
    "def load_numpy_arr_from_url(url):\n",
    "    \"\"\"\n",
    "    Loads a numpy array from surfdrive. \n",
    "    \n",
    "    Input:\n",
    "    url: Download link of dataset \n",
    "    \n",
    "    Outputs:\n",
    "    dataset: numpy array with input features or labels\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return np.load(io.BytesIO(response.content)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a1fdc-8c84-4829-b8c8-14c957f733f6",
   "metadata": {
    "id": "045a1fdc-8c84-4829-b8c8-14c957f733f6"
   },
   "source": [
    "# Task 1: Pattern Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b63ab-610e-4e03-b1da-a717c2a77c8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a45b63ab-610e-4e03-b1da-a717c2a77c8a",
    "outputId": "d6828a9b-d69a-4422-de7d-711606594d14"
   },
   "outputs": [],
   "source": [
    "# loading training and testing data for task 1\n",
    "# DO NOT MODIFY\n",
    "task1 = load_numpy_arr_from_url(\"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/task1data.npz?raw=true\")\n",
    "# task1 = np.load(\"task1data.npz\")\n",
    "\n",
    "X = torch.tensor(task1['arr_0']).float()\n",
    "y = torch.tensor(task1['arr_1']).float()\n",
    "\n",
    "X_train = X[:7500]\n",
    "X_val = X[7500:9500]\n",
    "X_test = X[9500:]\n",
    "y_train = y[:7500]\n",
    "y_val = y[7500:9500]\n",
    "y_test  = y[9500:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "\n",
    "print(f\"Carpet train shape: {X_train.shape}\")\n",
    "print(f\"Label train shape: {y_train.shape}\")\n",
    "print(f\"Carpet validation shape: {X_val.shape}\")\n",
    "print(f\"Label validation shape: {y_val.shape}\")\n",
    "print(f\"Carpet test shape: {X_test.shape}\")\n",
    "print(f\"Label test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5553f-023f-48fc-81b5-83184a46a21d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "a4c5553f-023f-48fc-81b5-83184a46a21d",
    "outputId": "a5988930-21d1-4615-9f26-2b82e33cb76f"
   },
   "outputs": [],
   "source": [
    "# random carpet\n",
    "idx = np.random.randint(0,7500)\n",
    "show_carpet(X_train, idx)\n",
    "print('Carpet from', oh_to_label(y_train[idx,None])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mEvRAcgEG8A9",
   "metadata": {
    "id": "mEvRAcgEG8A9"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 96*60\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7552cc3",
   "metadata": {
    "id": "f7552cc3"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f4986",
   "metadata": {
    "id": "a34f4986"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, n_epochs=10, device='cpu'):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "            train_correct += pred.eq(y.argmax(dim=1, keepdim=True)).sum().item()\n",
    "        train_acc = train_correct/len(train_loader.dataset)\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "          for X, y in val_loader:\n",
    "              X, y = X.to(device), y.to(device)\n",
    "              y_hat = model(X)\n",
    "              loss = criterion(y_hat, y)\n",
    "              val_loss += loss.item()\n",
    "              pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "              val_correct += pred.eq(y.argmax(dim=1, keepdim=True)).sum().item()\n",
    "        val_acc = val_correct/len(val_loader.dataset)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{n_epochs}: Train loss: {train_loss:.4f}, Train acc: {train_acc*100:.2f}, Val loss: {val_loss:.4f}, Val acc: {val_acc*100:.2f}')\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
    "\n",
    "# Test model\n",
    "def test(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            test_loss += F.cross_entropy(y_hat, y, reduction='sum').item()\n",
    "            pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.argmax(dim=1, keepdim=True)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'Test loss: {test_loss:.4f}, Test accuracy: {correct}/{len(test_loader.dataset)} ({correct/len(test_loader.dataset)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qH_igsANhueB",
   "metadata": {
    "id": "qH_igsANhueB"
   },
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "  def __init__(self, func):\n",
    "      super().__init__()\n",
    "      self.func = func\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.func(x)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    "\n",
    ")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jPlfFMQCow8L",
   "metadata": {
    "id": "jPlfFMQCow8L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plot_learning_curves(train_loss, train_accuracies, val_losses, val_accuracies):\n",
    "    # Plot the losses and accuracies\n",
    "    learning_curves = pd.DataFrame({'Train loss': train_losses, 'Train accuracy': train_accuracies, 'Validation loss': val_losses, 'Validation accuracy': val_accuracies})\n",
    "\n",
    "    print(\"Max val score: {:.2f}%\".format(learning_curves.iloc[:,3].max()*100))\n",
    "    learning_curves.plot(lw=2,style=['b:','r:','b-','r-'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022e9aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "2022e9aa",
    "outputId": "5f033f56-65d9-4df9-b580-544f285cca3c"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(model, train_loader, val_loader, optimizer, criterion, n_epochs=25, device=device)\n",
    "test(model, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5a8d4",
   "metadata": {
    "id": "06c5a8d4"
   },
   "source": [
    "## Task 1: Question 5d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otOZSx0EnlKY",
   "metadata": {
    "id": "otOZSx0EnlKY"
   },
   "source": [
    "### Different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YrsXA2RMqIU9",
   "metadata": {
    "id": "YrsXA2RMqIU9"
   },
   "outputs": [],
   "source": [
    "# Define new model to prevent ablation study to avoid messing with other results\n",
    "\n",
    "modelSGD = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    "\n",
    ")      \n",
    "\n",
    "modelSGD.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8735b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "37e8735b",
    "outputId": "2d933bb8-b94d-4692-d801-637bb4fc35e6"
   },
   "outputs": [],
   "source": [
    "optimizerSGD = torch.optim.SGD(modelSGD.parameters(), lr=0.001)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelSGD.to(device), train_loader, val_loader, optimizerSGD, criterion, n_epochs=25, device=device)\n",
    "test(modelSGD, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5KV9OIZWqkY-",
   "metadata": {
    "id": "5KV9OIZWqkY-"
   },
   "outputs": [],
   "source": [
    "# Define new model to prevent ablation study to avoid messing with other results\n",
    "\n",
    "modelAda = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    "\n",
    ")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NKoSTxI0pP4n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "NKoSTxI0pP4n",
    "outputId": "d9022b90-595f-42a6-df6c-2c813a5e3cfd"
   },
   "outputs": [],
   "source": [
    "modelAda.to(device)\n",
    "optimizerAdagrad = torch.optim.Adagrad(modelAda.parameters(), lr=0.001)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelAda, train_loader, val_loader, optimizerAdagrad, criterion, n_epochs=25, device=device)\n",
    "test(modelAda, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C6QOj9Iuqrf8",
   "metadata": {
    "id": "C6QOj9Iuqrf8"
   },
   "outputs": [],
   "source": [
    "# Define new model to prevent ablation study to avoid messing with other results\n",
    "\n",
    "modelRMS = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    "\n",
    ")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qVVzCutfpxhQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "qVVzCutfpxhQ",
    "outputId": "7241a2c8-ac85-4c9e-aea8-2525f89b6f63"
   },
   "outputs": [],
   "source": [
    "modelRMS.to(device)\n",
    "optimizerRMS = torch.optim.RMSprop(modelRMS.parameters(), lr=0.001)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelRMS, train_loader, val_loader, optimizerRMS, criterion, n_epochs=25, device=device)\n",
    "test(modelRMS, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BAKrpRTVqqWg",
   "metadata": {
    "id": "BAKrpRTVqqWg"
   },
   "source": [
    "### Changing train size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RmClYh8Pq506",
   "metadata": {
    "id": "RmClYh8Pq506"
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(task1['arr_0']).float()\n",
    "y = torch.tensor(task1['arr_1']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fUur5IJwqxy7",
   "metadata": {
    "id": "fUur5IJwqxy7"
   },
   "outputs": [],
   "source": [
    "# Define new model to prevent ablation study to avoid messing with other results\n",
    "\n",
    "modelLess = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    "\n",
    ")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I3BdeVnhqtYL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "I3BdeVnhqtYL",
    "outputId": "2c363f39-96bd-45ab-ce77-51d0b0bbd865"
   },
   "outputs": [],
   "source": [
    "# Less training\n",
    "X_train = X[:5000]\n",
    "X_val = X[5000:9500]\n",
    "X_test = X[9500:]\n",
    "y_train = y[:5000]\n",
    "y_val = y[5000:9500]\n",
    "y_test  = y[9500:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "modelLess.to(device)\n",
    "optimizer = torch.optim.Adam(modelLess.parameters(), lr=0.001)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelLess, train_loader, val_loader, optimizer, criterion, n_epochs=25, device=device)\n",
    "test(modelLess, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VaAr4AqTrVI5",
   "metadata": {
    "id": "VaAr4AqTrVI5"
   },
   "outputs": [],
   "source": [
    "# Define new model to prevent ablation study to avoid messing with other results\n",
    "\n",
    "modelMore = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    "\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ciIEgyrVcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09ciIEgyrVcf",
    "outputId": "82ad36eb-6e6a-4a45-f5fa-eb4852a562c8"
   },
   "outputs": [],
   "source": [
    "# More training\n",
    "X_train = X[:8500]\n",
    "X_val = X[8500:9500]\n",
    "X_test = X[9500:]\n",
    "y_train = y[:8500]\n",
    "y_val = y[8500:9500]\n",
    "y_test  = y[9500:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "modelMore.to(device)\n",
    "optimizer = torch.optim.Adam(modelMore.parameters(), lr=0.001)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelMore, train_loader, val_loader, optimizer, criterion, n_epochs=25, device=device)\n",
    "test(modelMore, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C6A8m6NErp59",
   "metadata": {
    "id": "C6A8m6NErp59"
   },
   "source": [
    "### Experimenting with more layers or less layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QscQo2_6rpYj",
   "metadata": {
    "id": "QscQo2_6rpYj"
   },
   "outputs": [],
   "source": [
    "# Less layers\n",
    "modelLessLayers = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    # nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    # nn.BatchNorm2d(16),\n",
    "    # nn.ReLU(),\n",
    "    # nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    # nn.BatchNorm2d(32),\n",
    "    # nn.ReLU(),\n",
    "\n",
    "    #block 2\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688, num_classes),           # Changed\n",
    "    # nn.BatchNorm1d(1024),                 # Removed\n",
    "    # nn.ReLU(),                            # Removed\n",
    "    # nn.Dropout(0.5),                      # Removed\n",
    "    # nn.Linear(1024, num_classes),         # Removed\n",
    "    nn.Softmax(dim=1)\n",
    ")      \n",
    "\n",
    "modelLessLayers.to(device)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelLessLayers, train_loader, val_loader, optimizer, criterion, n_epochs=25, device=device)\n",
    "test(modelLessLayers, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sLu-CZOBs3Z6",
   "metadata": {
    "id": "sLu-CZOBs3Z6"
   },
   "outputs": [],
   "source": [
    "# More layers\n",
    "modelMoreLayers = nn.Sequential(\n",
    "    \n",
    "    #block 1\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),   # Added\n",
    "    nn.BatchNorm2d(32),                                                     # Added\n",
    "    nn.ReLU(),                                                              # Added\n",
    "\n",
    "    #block 2\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 3\n",
    "\n",
    "    sc.Slice(rotation=1, reflection=False),\n",
    "    sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 4\n",
    "\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    #block 5\n",
    "\n",
    "    Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "    nn.Linear(2688 , 2048),                                               # Changed\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048 , 1024),                                               # Added\n",
    "    nn.BatchNorm1d(1024),                                                 # Added\n",
    "    nn.ReLU(),                                                            # Added\n",
    "    nn.Dropout(0.5),                                                      # Added\n",
    "    nn.Linear(1024 , 256),                                                # Added\n",
    "    nn.BatchNorm1d(256),                                                  # Added\n",
    "    nn.ReLU(),                                                            # Added\n",
    "    nn.Dropout(0.5),                                                      # Added\n",
    "    nn.Linear(256 , 64),                                                  # Added\n",
    "    nn.BatchNorm1d(64),                                                   # Added\n",
    "    nn.ReLU(),                                                            # Added\n",
    "    nn.Dropout(0.5),                                                      # Added\n",
    "    nn.Linear(64, num_classes),                                           # Added\n",
    "    nn.Softmax(dim=1)\n",
    ")      \n",
    "\n",
    "modelMoreLayers.to(device)\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(modelMoreLayers, train_loader, val_loader, optimizer, criterion, n_epochs=25, device=device)\n",
    "test(modelMoreLayers, test_loader, device=device)\n",
    "plot_learning_curves(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e988bc2-6ba1-49cd-ae26-6feea8ad2776",
   "metadata": {
    "id": "1e988bc2-6ba1-49cd-ae26-6feea8ad2776"
   },
   "source": [
    "# Task 2: Carpet Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2ce3a-4c8c-4f1f-9a29-113063ce7f74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20a2ce3a-4c8c-4f1f-9a29-113063ce7f74",
    "outputId": "01c33a2e-5531-498a-d085-eaa0231323a7"
   },
   "outputs": [],
   "source": [
    "# loading training and testing data for task 2\n",
    "# DO NOT MODIFY\n",
    "task2 = load_numpy_arr_from_url(\"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/task2data.npz?raw=true\")\n",
    "# task2 = np.load('task2data.npz')\n",
    "\n",
    "X = task2['arr_0'].astype(float)\n",
    "y = task2['arr_1'].astype(float)\n",
    "gt = task2['arr_2'].astype(float) # ground truth\n",
    "queries = task2['arr_3'].astype(float)\n",
    "targets = task2['arr_4'].astype(float)\n",
    "\n",
    "print(f\"Carpet train shape: {X.shape}\")\n",
    "print(f\"Label train shape: {y.shape}\")\n",
    "print(f\"Ground truth test shape: {gt.shape}\")\n",
    "print(f\"Query carpets shape: {queries.shape}\")\n",
    "print(f\"Candidate carpets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cc1db-e473-412e-b6b8-c95adc5438dd",
   "metadata": {
    "id": "fd0cc1db-e473-412e-b6b8-c95adc5438dd"
   },
   "outputs": [],
   "source": [
    "# function to determine performance of model\n",
    "def query_performance(net, queries, targets, gt, top=1):\n",
    "    assert top >= 1\n",
    "    cnt = 0\n",
    "    for i in range(gt.shape[0]):\n",
    "\n",
    "        q = queries[i][None].float().cuda()\n",
    "        t = targets[i].float().cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            \n",
    "            ### MODIFY IF NECESSARY ###\n",
    "            emb_q = net(q).cpu().numpy()\n",
    "            emb_t = net(t).cpu().numpy()\n",
    "\n",
    "            dists = cdist(emb_q, emb_t)\n",
    "            \n",
    "            if top == 1:\n",
    "                pred = np.argmin(dists)\n",
    "\n",
    "                if pred == gt[i]:\n",
    "                    cnt += 1\n",
    "            \n",
    "            else:\n",
    "                pred = np.argsort(dists)\n",
    "                if gt[i] in pred[0,:top].tolist():\n",
    "                    cnt+=1\n",
    "    return (100*cnt/gt.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "se77Cw5lYw2H",
   "metadata": {
    "id": "se77Cw5lYw2H"
   },
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "            \n",
    "        #block 1\n",
    "            \n",
    "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        #block 2\n",
    "\n",
    "        sc.Slice(rotation=4, reflection=False),\n",
    "        sc.SymmetryConv2d(32, 32, 4, stride=1, rotation=4, reflection=False),\n",
    "        sc.SymmetryPool(),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        #block 3\n",
    "\n",
    "        sc.Slice(rotation=1, reflection=False),\n",
    "        sc.SymmetryConv2d(32, 64, 3, stride=1, rotation=1, reflection=False),\n",
    "        sc.SymmetryPool(),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        #block 4\n",
    "\n",
    "        sc.Slice(rotation=4, reflection=False),\n",
    "        sc.SymmetryConv2d(64, 128, 8, stride=1, rotation=4, reflection=False),\n",
    "        sc.SymmetryPool(),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        #block 5\n",
    "        \n",
    "        Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "        nn.Linear(2688 , 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 200),\n",
    "        nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        #self.last_layer = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        #x = self.last_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_uqoSXIsZ88P",
   "metadata": {
    "id": "_uqoSXIsZ88P"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels))\n",
    "        self.label_to_indices = {label: np.where(  np.array(self.labels) == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size < self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V6syseTjaBFK",
   "metadata": {
    "id": "V6syseTjaBFK"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "class RandomTripletSelector():\n",
    "    \"\"\"\n",
    "    Select random negative  example for  each positive pair  to create triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RandomTripletSelector, self).__init__()\n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "\n",
    "            # random choose one negative example for each positive pair\n",
    "            temp_triplets = [[anchor_positive[0], anchor_positive[1], np.random.choice(negative_indices)] for anchor_positive in anchor_positives]\n",
    "            triplets += temp_triplets\n",
    "\n",
    "        return torch.LongTensor(np.array(triplets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QkQ0Z1k6rgTK",
   "metadata": {
    "id": "QkQ0Z1k6rgTK"
   },
   "outputs": [],
   "source": [
    "def pdist(vectors):\n",
    "    distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
    "        dim=1).view(-1, 1)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dExHzEHpq9c9",
   "metadata": {
    "id": "dExHzEHpq9c9"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "class Informative_Negative_TripletSelector():\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(Informative_Negative_TripletSelector, self).__init__()\n",
    "  \n",
    "        self.margin = margin\n",
    "  \n",
    "   # Our goal is to mining informative triplets.\n",
    "    def informative_negative(self, loss_values):\n",
    "        \n",
    "        informative_negative = np.where(loss_values > 0)[0]\n",
    "        return np.random.choice(informative_negative) if len(informative_negative) > 0 else None\n",
    "    \n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        \n",
    "        if torch.cuda.is_available()==False:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = pdist(embeddings)\n",
    "        distance_matrix = distance_matrix.cpu()\n",
    "\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "            anchor_positives = np.array(anchor_positives)\n",
    "\n",
    "            \n",
    "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
    "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
    "                loss_values = ap_distance - distance_matrix[torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "                \n",
    "                hard_negative = self.informative_negative(loss_values)\n",
    "                if hard_negative is not None:\n",
    "                    hard_negative = negative_indices[hard_negative]\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
    "\n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "\n",
    "        triplets = np.array(triplets)\n",
    "        \n",
    "        return torch.LongTensor(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_mwz7DG8aDhn",
   "metadata": {
    "id": "_mwz7DG8aDhn"
   },
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels.\n",
    "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
    "    triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "\n",
    "        if embeddings.is_cuda:\n",
    "            triplets = triplets.cuda()\n",
    "\n",
    "            \n",
    "        anchor_idx= triplets[:, 0]  \n",
    "        positive_idx= triplets[:, 1]  \n",
    "        negative_idx= triplets[:, 2]  \n",
    "            \n",
    "            \n",
    "        ap_distances = (embeddings[anchor_idx] - embeddings[positive_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        an_distances = (embeddings[anchor_idx] - embeddings[negative_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu((ap_distances - an_distances)/an_distances.mean() + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X4C39g-1dO_3",
   "metadata": {
    "id": "X4C39g-1dO_3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def run_trainer(self):\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            self.model.train()  # train mode\n",
    "            train_losses=[]\n",
    "            for batch in self.training_DataLoader:\n",
    "                x,y=batch\n",
    "                input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target)  # calculate loss\n",
    "                 \n",
    "                loss_value = loss.item()\n",
    "                train_losses.append(loss_value)\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "\n",
    "            self.model.eval()  # evaluation mode\n",
    "            valid_losses = []  # accumulate the losses here\n",
    "\n",
    "            for batch in self.validation_DataLoader:\n",
    "                x,y=batch\n",
    "                input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(input)   # one forward pass\n",
    "                    loss = self.criterion(out, target) # calculate loss\n",
    "                 \n",
    "                    loss_value = loss.item()\n",
    "                    valid_losses.append(loss_value)\n",
    "                \n",
    "            # print the results\n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clFDMSC-9hlm",
   "metadata": {
    "id": "clFDMSC-9hlm"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(X.astype(np.float32)[:12000]), torch.from_numpy(y.astype(np.float32)[:12000]))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X.astype(np.float32)[12000:]), torch.from_numpy(y.astype(np.float32)[12000:]))\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(y.astype(np.float32)[:12000], n_classes=20, n_samples=20)\n",
    "test_batch_sampler = BalancedBatchSampler(y.astype(np.float32)[12000:], n_classes=20, n_samples=20)\n",
    "\n",
    "triplets_train_loader = DataLoader(train_dataset, batch_sampler=train_batch_sampler)\n",
    "triplets_test_loader = DataLoader(test_dataset, batch_sampler=test_batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dul-2YgfdTIp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dul-2YgfdTIp",
    "outputId": "69c3c1e8-1cc2-409d-94fd-3f3dcfb06277"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "    \n",
    "# model\n",
    "embedding_net = EmbeddingNet()\n",
    "model = embedding_net.to(device)\n",
    "\n",
    "\n",
    "# margin value\n",
    "margin=1\n",
    "\n",
    "# criterion\n",
    "criterion = TripletLoss(margin,  RandomTripletSelector())\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=triplets_train_loader,\n",
    "                  validation_DataLoader=triplets_test_loader,\n",
    "                  epochs=10)\n",
    "\n",
    "# start training\n",
    "trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FefRGyLcoWkV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FefRGyLcoWkV",
    "outputId": "0040992f-a267-4783-f044-d54ad89ca7bf"
   },
   "outputs": [],
   "source": [
    "q = torch.from_numpy(queries).float().cuda()\n",
    "t = torch.from_numpy(targets).float().cuda()\n",
    "g = torch.from_numpy(gt).float().cuda()\n",
    "\n",
    "print(query_performance(model, q, t, g, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y6MCtJ6xCOlg",
   "metadata": {
    "id": "Y6MCtJ6xCOlg"
   },
   "outputs": [],
   "source": [
    "def extract_embeddings(dataloader, model):\n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), 200))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels\n",
    "\n",
    "train_embeddings, train_labels = extract_embeddings(triplets_train_loader, model)\n",
    "val_embeddings, val_labels = extract_embeddings(triplets_test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4-enpqwVDoD7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4-enpqwVDoD7",
    "outputId": "942997c8-35e1-4fde-e91f-9951e3b45bc4"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def plot_tsne_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
    "    \n",
    "    \n",
    "    # The first 3000 embeddings and targets\n",
    "    embeddings= embeddings[:3000]\n",
    "    targets= targets[:3000]\n",
    "\n",
    "    # Using Tsne to for dimension reduction \n",
    "    tsne = TSNE(n_components=2)\n",
    "    embeddings = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(10):\n",
    "        inds = np.where(targets==i)[0]\n",
    "        plt.scatter(embeddings[inds,0], embeddings[inds,1], alpha=0.5)\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    # plt.legend(classes)\n",
    "\n",
    "plot_tsne_embeddings(train_embeddings, train_labels)\n",
    "plot_tsne_embeddings(val_embeddings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1MAGVUIzYndk",
   "metadata": {
    "id": "1MAGVUIzYndk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
